{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d269a8-5dcf-41ab-a276-02acd6ba318e",
   "metadata": {},
   "source": [
    "# Demo 3. Workflow for setting up sampling and simulations\n",
    "\n",
    "This demo walks through setting up a simulation experiment from the start, using the 2-parameter classical balanced network (from Brunel 2000) as the simulator. \n",
    "\n",
    "![Balanced network with 1.5ms synaptic delay.](../assets/img/brunel_2000.png)\n",
    "\n",
    "\n",
    "We will walk through: \n",
    "- defining free parameters and ranges\n",
    "- constructing the proposal (prior) distribution\n",
    "- sampling from it and saving those samples\n",
    "- simulating at scale and saving out the simulation data\n",
    "- managing the whole workflow with hydra\n",
    "\n",
    "By the end of this tutorial, you will get a sense of the workflow and infrastructure to run many simulations, analyzing that data, and getting it ready for training deep generative models.\n",
    "\n",
    "For more details, visit the [AutoMIND preprint](https://www.biorxiv.org/content/10.1101/2024.08.21.608969v1).\n",
    "\n",
    "---\n",
    "<!-- ---\n",
    "Note: to run this notebook live, you will first need to download and unzip the trained DGMs and example dataset. You can find them from the data repository links on the [homepage](https://github.com/mackelab/automind), and you should place them in the appropriate directories by following the included instructions (or simply change the datapaths below). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0a01dc-000f-4a14-96c7-591c3c079b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mpl_rc = \"../assets/matplotlibrc\"\n",
    "plt.style.use(mpl_rc)\n",
    "\n",
    "import brian2 as b2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from torch.distributions import Uniform\n",
    "from automind.sim import runners, b2_interface\n",
    "from automind.utils import data_utils, analysis_utils, plot_utils, dist_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71408d3-5b8c-4a02-9a44-71e367f1fcd0",
   "metadata": {},
   "source": [
    "Specifying the output folder (note this step would be automatically taken care of by `hydra`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd65ac2d-eb38-4ba5-86b0-a31ed8be4457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': '../datasets/brunel_2000//data/',\n",
       " 'figures': '../datasets/brunel_2000//figures/'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'brunel_2000'\n",
    "data_path = f'../datasets/{experiment_name}/'\n",
    "\n",
    "# This helper makes a number of subfolders you can specify. By default, we have 'data' and 'figures'.\n",
    "path_dict = data_utils.make_subfolders(data_path)\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217793b-03d9-453a-aeb5-3d3b5e707b49",
   "metadata": {},
   "source": [
    "First, we load the default parameter settings for the Brunel network. Since this model has fewer free parameters and no E/I neuron-specific parameters, they are all kept under 'params_net'.\n",
    "Parameters include neuronal, network, and synaptic parameters, as well as simulations settings and analysis parameters. \n",
    "\n",
    "In the cell after, we make changes to these default values, such as simulation time, cells recorded from, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55bc82c-9449-4e75-ae03-ff49a1b7d332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params_net': {'N_pop': 12500,\n",
       "  'exc_prop': 0.8,\n",
       "  'N_external': 1000,\n",
       "  'v_0': None,\n",
       "  'v_rest': 0. * volt,\n",
       "  'v_reset': 10. * mvolt,\n",
       "  'v_thresh': 20. * mvolt,\n",
       "  'tau_m': 20. * msecond,\n",
       "  't_refrac': 2. * msecond,\n",
       "  't_syn_delay': 1.5 * msecond,\n",
       "  'w0': 100. * uvolt,\n",
       "  'p_connect': 0.1,\n",
       "  'w_external': 100. * uvolt,\n",
       "  'g': 4,\n",
       "  'nu_ext': 1.2},\n",
       " 'params_analysis': {'t_early_stop': 1.1 * second,\n",
       "  'early_stop_window': array([0.1, 1.1]),\n",
       "  'early_stopped': False,\n",
       "  'stop_fr_norm': (0.0001, 0.99),\n",
       "  'do_spikes': True,\n",
       "  'pop_sampler': {'exc': None},\n",
       "  'analysis_window': array([0.1, None], dtype=object),\n",
       "  'smooth_std': 0.0005,\n",
       "  'dt_poprate': 1. * msecond,\n",
       "  'min_num_spikes': 3,\n",
       "  'do_bursts': True,\n",
       "  'use_burst_prominence': True,\n",
       "  'min_burst_height': 5,\n",
       "  'min_burst_height_ratio': 0.5,\n",
       "  'min_burst_distance': 1.0,\n",
       "  'burst_win': [-0.5, 2.5],\n",
       "  'burst_wlen': 10,\n",
       "  'burst_rel_height': 0.95,\n",
       "  'do_psd': False,\n",
       "  'nperseg_ratio': 0.5,\n",
       "  'noverlap_ratio': 0.75,\n",
       "  'f_lim': 500,\n",
       "  'do_pca': False,\n",
       "  'n_pcs': 100,\n",
       "  'pca_bin_width': 10. * msecond,\n",
       "  'pca_smooth_std': 50. * msecond},\n",
       " 'params_settings': {'experiment': None,\n",
       "  'network_type': 'brunel',\n",
       "  'sim_time': 1.1 * second,\n",
       "  'dt': 200. * usecond,\n",
       "  'dt_ts': 1. * msecond,\n",
       "  'batch_seed': 0,\n",
       "  'random_seed': 42,\n",
       "  'record_defs': {'exc': {'rate': True,\n",
       "    'spikes': False,\n",
       "    'trace': (['I'], array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))}},\n",
       "  'save_sigdigs': 6,\n",
       "  't_sigdigs': 4,\n",
       "  'integ_method': 'euler',\n",
       "  'real_run_time': 0.0,\n",
       "  't_sigs': 4}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict = runners.construct_experiment_settings_brunel()\n",
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6708af0e-d548-4c18-af24-f27b01f76172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change experiment name and batch seed\n",
    "params_dict['params_settings'][\"experiment\"]= experiment_name\n",
    "params_dict['params_settings']['batch_seed'] = 1337\n",
    "params_dict['path_dict'] = path_dict\n",
    "\n",
    "# Define the cells we record from, and whether to record population rates and intracellular variables\n",
    "N_record_exc, N_record_inh = 1000, 250\n",
    "population_defs = {\n",
    "    \"exc\": {\"rate\": False, \"spikes\": N_record_exc, \"trace\": False},\n",
    "    \"inh\": {\"rate\": False, \"spikes\": N_record_inh, \"trace\": False},\n",
    "}\n",
    "\n",
    "params_dict['params_settings'][\"record_defs\"] = population_defs\n",
    "params_dict['params_settings'][\"sim_time\"] = 10.1*b2.second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffff436-8ea5-48ea-a726-2c6b8a17cf0d",
   "metadata": {},
   "source": [
    "There is also a helper function to update many parameters in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8b4b15-e176-434e-a60c-ec87c0be1a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t_early_stop': 1.1 * second,\n",
       " 'early_stop_window': array([0.1, 1.1]),\n",
       " 'early_stopped': False,\n",
       " 'stop_fr_norm': (0.0001, 0.99),\n",
       " 'do_spikes': True,\n",
       " 'pop_sampler': {'exc': None},\n",
       " 'analysis_window': [1.1, None],\n",
       " 'smooth_std': 0.0005,\n",
       " 'dt_poprate': 200. * usecond,\n",
       " 'min_num_spikes': 3,\n",
       " 'do_bursts': False,\n",
       " 'use_burst_prominence': True,\n",
       " 'min_burst_height': 5,\n",
       " 'min_burst_height_ratio': 0.5,\n",
       " 'min_burst_distance': 1.0,\n",
       " 'burst_win': [-0.5, 2.5],\n",
       " 'burst_wlen': 10,\n",
       " 'burst_rel_height': 0.95,\n",
       " 'do_psd': True,\n",
       " 'nperseg_ratio': 1,\n",
       " 'noverlap_ratio': 0.75,\n",
       " 'f_lim': 2400,\n",
       " 'do_pca': False,\n",
       " 'n_pcs': 100,\n",
       " 'pca_bin_width': 10. * msecond,\n",
       " 'pca_smooth_std': 50. * msecond,\n",
       " 'summary_set_name': 'MK1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_settings_update = {\n",
    "    \"params_analysis.summary_set_name\": \"MK1\",\n",
    "    \"params_analysis.do_spikes\": True,\n",
    "    \"params_analysis.do_psd\": True,\n",
    "    \"params_analysis.do_bursts\": False,\n",
    "    \"params_analysis.do_pca\": False,\n",
    "    \n",
    "    \"params_analysis.analysis_window\": [1.1, None],\n",
    "    \"params_analysis.pop_sampler\": {\"exc\": None},\n",
    "\n",
    "    \"params_analysis.dt_poprate\": 0.2 * b2.msecond,\n",
    "    \"params_analysis.smooth_std\": 0.0005,\n",
    "    \n",
    "    \"params_analysis.nperseg_ratio\": 1,\n",
    "    \"params_analysis.f_lim\": 2400,\n",
    "}\n",
    "params_dict = data_utils.update_params_dict(params_dict, analysis_settings_update)\n",
    "params_dict['params_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c05635-01d4-44c2-9f8b-c4e02c8b0362",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we define which network parameters are free variables, and their proposal distribution. \n",
    "\n",
    "In this case, we pick g and nu to be uniformly distributed, with bounds defined as the original Brunel phase diagram.\n",
    "\n",
    "Note that, if we wanted to make an additional parameter a free variable, like delay time, we simply have to define it in this object (e.g., the commented out line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bc4496-18be-4197-91f6-d38253baa05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params_net.g (1.0) ~ Uniform(low: 0.0, high: 8.0) \n",
       "params_net.nu_ext (1.0) ~ Uniform(low: 0.0, high: 4.0) "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_params = [\n",
    "    [\"params_net.g\", Uniform, {\"low\": 0., \"high\": 8.}, 1.0],\n",
    "    [\"params_net.nu_ext\", Uniform, {\"low\": 0., \"high\": 4.}, 1.0],\n",
    "    # [\"params_net.t_syn_delay\", Uniform, {\"low\": 1., \"high\": 3.}, b2.msecond],\n",
    "]\n",
    "\n",
    "proposal = dist_utils.CustomIndependentJoint(variable_params)\n",
    "proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529aa5d-1d5b-4ef5-9413-f54879aa6b36",
   "metadata": {},
   "source": [
    "Then, we sample from the 2D Uniform proposal distribution, and put them into a pandas dataframe.\n",
    "\n",
    "In addition, we append the global (batch) seed and per-simulation random seed to the samples as identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79be5d02-8f42-4a77-a0d7-b43d9ffd3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "samples = proposal.sample((n_samples,)).numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1798ec-7ba6-45c9-87a3-fd9707b8748c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params_settings.batch_seed</th>\n",
       "      <th>params_settings.random_seed</th>\n",
       "      <th>params_net.g</th>\n",
       "      <th>params_net.nu_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1337</td>\n",
       "      <td>15</td>\n",
       "      <td>1.340242</td>\n",
       "      <td>2.529829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1337</td>\n",
       "      <td>56</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>2.325385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337</td>\n",
       "      <td>115</td>\n",
       "      <td>4.724340</td>\n",
       "      <td>1.362440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337</td>\n",
       "      <td>259</td>\n",
       "      <td>2.559706</td>\n",
       "      <td>3.425283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337</td>\n",
       "      <td>457</td>\n",
       "      <td>6.917793</td>\n",
       "      <td>2.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1337</td>\n",
       "      <td>747</td>\n",
       "      <td>4.915948</td>\n",
       "      <td>0.948571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1337</td>\n",
       "      <td>801</td>\n",
       "      <td>5.181352</td>\n",
       "      <td>0.518551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1337</td>\n",
       "      <td>811</td>\n",
       "      <td>4.511281</td>\n",
       "      <td>3.638246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1337</td>\n",
       "      <td>845</td>\n",
       "      <td>7.639732</td>\n",
       "      <td>1.265175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1337</td>\n",
       "      <td>977</td>\n",
       "      <td>6.479698</td>\n",
       "      <td>2.965006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   params_settings.batch_seed  params_settings.random_seed  params_net.g  \\\n",
       "0                        1337                           15      1.340242   \n",
       "1                        1337                           56      7.033333   \n",
       "2                        1337                          115      4.724340   \n",
       "3                        1337                          259      2.559706   \n",
       "4                        1337                          457      6.917793   \n",
       "5                        1337                          747      4.915948   \n",
       "6                        1337                          801      5.181352   \n",
       "7                        1337                          811      4.511281   \n",
       "8                        1337                          845      7.639732   \n",
       "9                        1337                          977      6.479698   \n",
       "\n",
       "   params_net.nu_ext  \n",
       "0           2.529829  \n",
       "1           2.325385  \n",
       "2           1.362440  \n",
       "3           3.425283  \n",
       "4           2.230900  \n",
       "5           0.948571  \n",
       "6           0.518551  \n",
       "7           3.638246  \n",
       "8           1.265175  \n",
       "9           2.965006  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get random seeds\n",
    "batch_seed = params_dict['params_settings']['batch_seed']\n",
    "\n",
    "# Set all seeds so random seed draws are consistent given batch seed\n",
    "data_utils.set_all_seeds(batch_seed)\n",
    "random_seeds = np.random.choice(a=int(n_samples * 100), size=n_samples, replace=False) # Avoid random_seed collision\n",
    "\n",
    "# Put everything into a dataframe for record keeping\n",
    "df_proposal_samples = pd.DataFrame(samples, columns=proposal.names)\n",
    "df_proposal_samples.insert(loc=0, column=\"params_settings.batch_seed\", value=batch_seed)\n",
    "df_proposal_samples.insert(loc=1,column=\"params_settings.random_seed\",value=random_seeds,)\n",
    "df_proposal_samples = df_proposal_samples.sort_values(\"params_settings.random_seed\", ignore_index=True)\n",
    "df_proposal_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b220b-da44-4357-8a17-0ff87ab5820e",
   "metadata": {},
   "source": [
    "Everything is now prepared for simulations, and we save out the proposal distribution object, the simulation configuration, and the samples themselves out to a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99147375-d264-40c6-8851-bce329799fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = params_dict['path_dict']['data']\n",
    "data_utils.save_params_priors(save_path, params_dict, proposal)\n",
    "data_utils.save_samples_to_csv(df_proposal_samples, save_path, batch_seed, dist_type='prior')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441a7f8-5eb0-4afa-8b89-2d31110eefe0",
   "metadata": {},
   "source": [
    "---\n",
    "All of the above are setup operations. From here, we can load back the saved samples and distribution, and run the simulations.\n",
    "\n",
    "The next couple of cells seem redundant, because we're loading back what we just saved out. But it's just to demonstrate a separation in the workflow: \n",
    "\n",
    "By partitioning the workflow as such, we can take advantage of the same modularity for posterior simulations. In other words, the proposal distribution can be replaced by an inferred posterior distribution, and the saved samples in the csv file can be posterior samples, or any samples, if some intervention is manually applied (e.g., setting all input strength to 0).\n",
    "\n",
    "To simulate, we just need to load these files, and running the simulation is agnostic to where these samples come from (steps are similar to in Demo 1 and 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8515d4c5-4aea-4ed8-ab60-0d6c61f42d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples.csv ['1337_prior_samples.csv']\n",
      "prior.pickle ['prior.pickle']\n",
      "params_dict_default.pickle ['params_dict_default.pickle']\n"
     ]
    }
   ],
   "source": [
    "# Convenience function to extract full path of objects with a certain filename\n",
    "filenames = data_utils.extract_data_files(save_path, file_type_list=['samples.csv', 'prior.pickle', 'params_dict_default.pickle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fdd0e53-3906-435d-b8c5-37241fd4884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    /opt/miniconda3/envs/automind/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      " [py.warnings]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_settings.batch_seed has no prior. Copied as bare value without unit.\n",
      "params_settings.random_seed has no prior. Copied as bare value without unit.\n"
     ]
    }
   ],
   "source": [
    "# Load params dictionary, proposal distribution, and samples from path\n",
    "proposal = data_utils.load_pickled(save_path+filenames['prior'])\n",
    "params_dict = data_utils.load_pickled(save_path+filenames['params_dict_default'])\n",
    "df_proposal_samples = pd.read_csv(save_path+filenames['samples'], index_col=0)\n",
    "\n",
    "\n",
    "# Plug samples into list of param dictionaries for simulation\n",
    "params_dict_list = data_utils.fill_params_dict(\n",
    "    params_dict, df_proposal_samples, proposal.as_dict, n_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefc791-d5b7-4992-a5ae-4fb43e8f5499",
   "metadata": {},
   "source": [
    "---\n",
    "### Simulating\n",
    "Now we simply run the simulations, defined by the parameters in the list of parameter samples. Again, we parallelize the simulations with `multiprocessing`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b672fe-1817-4a55-bc0b-f7876c283d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache non-existent.\n",
      "1337-56|1337-115|1337-259|1337-15|1337-457|1337-747|1337-801|1337-811|1337-845|1337-977|Simulations took 21.27 seconds.\n",
      "cache non-existent.\n"
     ]
    }
   ],
   "source": [
    "cache_path = \"./.cache/\"\n",
    "b2_interface.clear_b2_cache(cache_path)\n",
    "b2_interface.set_b2_cache(cache_path, True)\n",
    "\n",
    "n_cores = 5\n",
    "sim_parallel = True\n",
    "if sim_parallel:\n",
    "    from multiprocessing import Pool\n",
    "    start_time = time()\n",
    "    with Pool(n_cores) as pool:\n",
    "        sim_collector = pool.map(runners.run_simulator, params_dict_list)\n",
    "    print(f\"Simulations took {time()-start_time:.2f} seconds.\")\n",
    "else:\n",
    "    sim_collector = []\n",
    "    for i_sim in range(n_samples):\n",
    "        start_time = time()\n",
    "        sim_collector.append(runners.run_simulator(params_dict_list[i_sim]))\n",
    "        print(f\"Simulation {i_sim+1}/{n_samples} took {time()-start_time:.2f} seconds.\")\n",
    "\n",
    "b2_interface.clear_b2_cache(cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e3212-783a-45e6-a5b7-759faf1b49f7",
   "metadata": {},
   "source": [
    "---\n",
    "We will also save out the simulations to a `h5` file. The filepath is readout from the `params_dict` object, i.e., the same folder the prior samples are saved in as well.\n",
    "\n",
    "The same function also saves figures of the population firing rates in the `/figures` subdirectory (parallel to `/data`) for quick visual analysis. It automatically skips models that had no spikes. \n",
    "\n",
    "Turn this off if you are running many simulations because it will make many small files on a cluster, and admins usually don't love that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59d42e37-f7c3-4e4d-b909-6d8691f3a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_path = data_utils.save_h5_and_plot_raw(sim_collector, do_plot_ts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38b743-eb5a-427d-8daa-695611cefca9",
   "metadata": {},
   "source": [
    "We can analyze these simulations as before, even extracting the same summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7e29fd-8d6f-4de6-97ef-38b1524d4930",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_collector = [\n",
    "    analysis_utils.compute_summary_features(sims[1], sims[0]) for sims in sim_collector\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c11073-a48e-4d97-b9f8-b6698e9b30e2",
   "metadata": {},
   "source": [
    "Finally, we can plot the simulations and their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43231f04-b9c5-4bb5-af97-e0c9c85ee287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "# Plot the results\n",
    "xlims = [0, 1]\n",
    "xlims_zoom = [0.1, 0.2]\n",
    "every_other = 1\n",
    "for i_sim, results in enumerate(results_collector):\n",
    "    if results['summary_spikes']['isi_numspks_mu'].values==0:\n",
    "        continue\n",
    "        \n",
    "    fig = plt.figure(figsize=(4.0, .8))\n",
    "\n",
    "    gs = gridspec.GridSpec(2, 3, width_ratios=[1.5, 1.5, 1], height_ratios=[1, 1])\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax3 = fig.add_subplot(gs[0, 1])\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax5 = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "    # Plot raster, rates, and PSD\n",
    "    params = sim_collector[i_sim][0]\n",
    "    plot_utils._plot_raster_pretty(\n",
    "        sim_collector[i_sim][1], XL=xlims, every_other=10, fontsize=5, ax=ax1, ms=0.02\n",
    "    )\n",
    "    plot_utils._plot_rates_pretty(\n",
    "        results[\"pop_rates\"],\n",
    "        XL=xlims,\n",
    "        pops_to_plot=[\"avgpop_rate\"],\n",
    "        ylim_past=1 * 1000,\n",
    "        fontsize=5,\n",
    "        ax=ax2,\n",
    "        color=\"k\",\n",
    "        lw=0.1,\n",
    "    )\n",
    "    ax2.set_ylabel(\"Rate\", labelpad=-5)\n",
    "\n",
    "    plot_utils._plot_raster_pretty(\n",
    "        sim_collector[i_sim][1], XL=xlims_zoom, every_other=every_other, fontsize=5, ax=ax3, ms=0.02\n",
    "    )\n",
    "    plot_utils._plot_rates_pretty(\n",
    "        results[\"pop_rates\"],\n",
    "        XL=xlims_zoom,\n",
    "        pops_to_plot=[\"avgpop_rate\"],\n",
    "        ylim_past=1 * 1000,\n",
    "        fontsize=5,\n",
    "        ax=ax4,\n",
    "        color=\"k\",\n",
    "        lw=0.2\n",
    "    )\n",
    "    plot_utils._plot_psd_pretty(\n",
    "        results[\"summary_psd\"], [\"avgpop_rate\"], ax5, fontsize=5, alpha=0.8, lw=0.5\n",
    "    )\n",
    "    ax5.set_xlim([0.5, 2400])\n",
    "    ax5.set_xticks([1, 10, 100, 1000])\n",
    "    ax2.set_ylabel(\"Rate\", labelpad=-5)\n",
    "    ax3.set_ylabel(\"\")\n",
    "    ax4.set_ylabel(\"\")\n",
    "    ax4.set_yticks([])\n",
    "    ax1.set_title(f\"g={params['params_net']['g']:.2f}, input={params['params_net']['nu_ext']:.2f}\",pad=0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128c7f8-2a1b-4732-86ad-bbb7e3efb312",
   "metadata": {},
   "source": [
    "---\n",
    "# That's all!\n",
    "\n",
    "This whole workflow, with some additional checks and automation, including using hydra for path management, is included as a script in `../experiments/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
